<div class="title" align=center>
    <h1>Audio Dataset VPR Classifier</h1>
	<div>éŸ³é¢‘æ•°æ®é›†å£°çº¹è¯†åˆ«åˆ†ç±»å™¨</div>
    <br/>
    <p>
        <img src="https://img.shields.io/github/license/2DIPW/audio_dataset_vpr">
    	<img src="https://img.shields.io/badge/python-3.8-blue">
        <img src="https://img.shields.io/github/stars/2DIPW/audio_dataset_vpr?style=social">
        
</div>

ç®€ä½“ä¸­æ–‡ | [English](https://github.com/2DIPW/audio_dataset_vpr/blob/master/README_EN.md)

## ğŸš© ç®€ä»‹
ä¸€ä¸ªåŸºäºEcapaTdnnå£°çº¹è¯†åˆ«æ¨¡å‹å¯¹éŸ³é¢‘æ•°æ®é›†æŒ‰è¯´è¯äººè‡ªåŠ¨åˆ†ç±»çš„æ•°æ®é›†ç­›é€‰è¾…åŠ©å·¥å…·ï¼Œä»…éœ€ä¸ºæ¯ä¸ªè¯´è¯äººå‡†å¤‡æ•°æ¡ä»£è¡¨æ€§çš„è¯­éŸ³ç‰‡æ®µï¼Œå¯ç”¨äºè¾…åŠ© VITS/SoVITS/Diff-SVC/RVC/DDSP-SVC ç­‰è¯­éŸ³æ¨¡å‹æ•°æ®é›†çš„åˆ¶ä½œã€‚

åŸºäº [yeyupiaoling/VoiceprintRecognition-Pytorch](https://github.com/yeyupiaoling/VoiceprintRecognition-Pytorch) ä¿®æ”¹ï¼Œå¢åŠ äº†æ‰¹é‡å£°çº¹è¯†åˆ«åŠŸèƒ½ï¼Œå¹¶èƒ½å°†è¯†åˆ«ç»“æœä¿å­˜ä¸ºå¯å¯¼å…¥ [2DIPW/audio_dataset_screener](https://github.com/2DIPW/audio_dataset_screener) ä¸­è¿›è¡Œè¿›ä¸€æ­¥æ‰‹å·¥ç­›é€‰çš„ JSON å·¥ç¨‹æ–‡ä»¶ã€‚ç›¸æ¯”åŸé¡¹ç›®åˆ é™¤äº†æ‰€æœ‰ä¸æ¨¡å‹è®­ç»ƒç›¸å…³çš„æºç ï¼Œæ•…å¦‚éœ€è®­ç»ƒè‡ªå·±çš„æ¨¡å‹è¯·ä½¿ç”¨åŸé¡¹ç›®ã€‚

æ­¤é¡¹ç›®ä¸ºå®éªŒæ€§é¡¹ç›®ï¼Œä¸ä¿è¯ä½¿ç”¨æ•ˆæœï¼Œä»…ä¾›å­¦ä¹ ä¸äº¤æµï¼Œå¹¶éä¸ºç”Ÿäº§ç¯å¢ƒå‡†å¤‡ã€‚

## ğŸ“¥ éƒ¨ç½²
### å…‹éš†
```shell
git clone https://github.com/2DIPW/audio_dataset_vpr.git
cd audio_dataset_vpr
```
### åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆå¯é€‰ï¼Œä»¥Anacondaä¸ºä¾‹ï¼‰
```sheel
conda create -n ad-vpr python=3.8
conda activate ad-vpr
```
### å®‰è£…PyTorch
- æ ¹æ®éœ€æ±‚å®‰è£… PyTorchï¼Œè¯¦è§[å®˜ç½‘](https://pytorch.org/get-started/locally)ï¼Œä»¥ä¸‹ä¸º pip å®‰è£… PyTorch-CUDA ç‰ˆæœ¬çš„ç¤ºä¾‹ã€‚å¦‚æœå·²ç»å®‰è£…ï¼Œè¯·è·³è¿‡ã€‚
```shell
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```
### å®‰è£…å…¶ä»–ä¾èµ–
```shell
pip install -r requirements.txt
```
### é…ç½®å£°çº¹è¯†åˆ«æ¨¡å‹
é»˜è®¤å‚æ•°ä¸‹ï¼Œä½ éœ€è¦å°†æ¨¡å‹æ–‡ä»¶`model.pt`ã€`model.state`ã€`optimizer.pt`åŠé…ç½®æ–‡ä»¶`config.yml`ç½®äº`model`ç›®å½•ã€‚ä½ ä¹Ÿå¯ä»¥é€šè¿‡æŒ‡å®š`-m`å’Œ`-c`å‚æ•°è¯»å–å…¶ä»–è·¯å¾„ä¸‹çš„æ¨¡å‹åŠé…ç½®æ–‡ä»¶ã€‚

- ä½ å¯ä»¥ä» Hugging Face ä¸‹è½½æˆ‘åŸºäº [zhvoice](https://aistudio.baidu.com/aistudio/datasetdetail/133922) æ•°æ®é›†è®­ç»ƒçš„ EcapaTdnn æ¨¡å‹ï¼š[2DIPW/VPR_zhvoice_EcapaTdnn](https://huggingface.co/2DIPW/VPR_zhvoice_EcapaTdnn/tree/main)
- æˆ–è€…ä¸‹è½½[åŸé¡¹ç›®ä½œè€…è®­ç»ƒçš„æ›´å¤šæ¨¡å‹](https://github.com/yeyupiaoling/VoiceprintRecognition-Pytorch#%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD)
- æˆ–è€…åŸºäºåŸé¡¹ç›®[è®­ç»ƒè‡ªå·±çš„æ¨¡å‹](https://github.com/yeyupiaoling/VoiceprintRecognition-Pytorch#%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE)

å£°çº¹è¯†åˆ«æ¨¡å‹çš„è´¨é‡ä¸è¯†åˆ«æ•ˆæœç›´æ¥ç›¸å…³ï¼Œä½ å¯ä»¥è‡ªè¡Œå°è¯•æ‘¸ç´¢æœ€ä½³çš„æ¨¡å‹ã€‚
## ğŸ— ä½¿ç”¨æ–¹æ³•
### å‡†å¤‡éŸ³é¢‘ç‰¹å¾åº“
- å¯¹äºæ¯ä¸ªè¯´è¯äººï¼Œé€‰å–å‡ æ®µæœ€å…·ä»£è¡¨æ€§çš„è¯­éŸ³ç‰‡æ®µï¼ŒæŒ‰ä»¥ä¸‹æ–‡ä»¶ç»“æ„æ”¾å…¥`labels`ç›®å½•ã€‚æ¯ä¸ªè¯´è¯äººå»ºç«‹ä¸€ä¸ªå­ç›®å½•ï¼Œç›®å½•åä¸ºè¯´è¯äººåç§°ï¼Œæ–‡ä»¶åä¸åšè¦æ±‚ã€‚
- ç”±äºä»£ç æ˜¯æ ¹æ®ç›¸ä¼¼åº¦å¤§äºç»™å®šé˜ˆå€¼çš„ç‰¹å¾ç‰‡æ®µæ•°é‡æ¥åˆ¤å®šè¯´è¯äººçš„ï¼Œè¯·ä¿è¯æ¯ä¸ªè¯´è¯äººç‰¹å¾è¯­éŸ³ç‰‡æ®µ**æ•°é‡ç›¸ç­‰**ã€‚
- å¦‚æœä½ æƒ³å°†å£°çº¹è¯†åˆ«ç»“æœç”¨äº Audio Dataset Screener çš„åç»­æ‰‹å·¥ç­›é€‰ï¼Œè¯´è¯äººä¸åº”è¶…è¿‡5ä½ï¼Œå¦åˆ™åºå·å¤§äº5çš„è¯´è¯äººä¼šè¢« Audio Dataset Screener è‡ªåŠ¨å¿½ç•¥ã€‚

    ```
    input
    â”œâ”€â”€â”€speaker1
    â”‚   â”œâ”€â”€â”€xxx1-xxx1.wav
    â”‚   â”œâ”€â”€â”€...
    â”‚   â””â”€â”€â”€xxx1-xxx4.wav
    â””â”€â”€â”€speaker2
        â”œâ”€â”€â”€xxx2-xxx1.wav
        â”œâ”€â”€â”€...
        â””â”€â”€â”€xxx2-xxx4.wav
    ```
### å‡†å¤‡å¾…åˆ†ç±»çš„éŸ³é¢‘æ–‡ä»¶
- é»˜è®¤å‚æ•°ä¸‹ï¼Œä½ éœ€è¦å°†æ‰€æœ‰å¾…åˆ†ç±»çš„éŸ³é¢‘ç‰‡æ®µï¼ˆwavæ ¼å¼ï¼‰æ”¾å…¥`input`ç›®å½•ã€‚ä½ ä¹Ÿå¯ä»¥é€šè¿‡æŒ‡å®š`-i`å‚æ•°è¯»å–å…¶ä»–è·¯å¾„ä¸‹çš„éŸ³é¢‘ç‰‡æ®µã€‚
### è¿è¡Œè¯†åˆ«åˆ†ç±»
- ä½¿ç”¨`infer.py`
    ```shell
    python infer.py
    ```
    å¯æŒ‡å®šçš„å‚æ•°:
    - `-m` | `--model_path`: å­˜æ”¾å£°çº¹è¯†åˆ«æ¨¡å‹çš„ç›®å½•ã€‚é»˜è®¤å€¼ï¼š`model/`
    - `-c` | `--configs`: æ¨¡å‹é…ç½®æ–‡ä»¶çš„è·¯å¾„ã€‚é»˜è®¤å€¼ï¼š`model/config.yml`
    - `-d` | `--device`: æ¨ç†è®¾å¤‡ï¼Œgpuæˆ–cpuã€‚é»˜è®¤å€¼ï¼š`gpu`
    - `-l` | `--label_path`: å­˜æ”¾éŸ³é¢‘ç‰¹å¾åº“çš„ç›®å½•ã€‚é»˜è®¤å€¼ï¼š`labels/`
    - `-t` | `--threshold`: åˆ¤å®šé˜ˆå€¼ï¼Œè‹¥ç½®ä¿¡åº¦å¤§äºè¯¥å€¼åˆ™è®¤ä¸ºç‰¹å¾ç›¸ç¬¦ã€‚é»˜è®¤å€¼ï¼š`0.6`
    - `-i` | `--input_path`: å­˜æ”¾å¾…åˆ†ç±»éŸ³é¢‘æ–‡ä»¶çš„ç›®å½•ã€‚é»˜è®¤å€¼ï¼š`input/`
    - `-o` | `--output_path`: å­˜æ”¾åˆ†ç±»ç»“æœçš„ç›®å½•ã€‚é»˜è®¤å€¼ï¼š`output/`

- è¯†åˆ«ç»“æŸåï¼Œè¾“å…¥çš„éŸ³é¢‘æ–‡ä»¶å°†ä¼šè¢«ç§»åŠ¨è‡³`output`ç›®å½•ä¸‹çš„ä»¥`VPR_Result_YYYYMMDD_HHMMSS`æ ¼å¼å‘½åçš„ç›®å½•ä¸­ï¼Œè¯†åˆ«ä¸ºä¸åŒè¯´è¯äººçš„éŸ³é¢‘æ–‡ä»¶å°†ä¼šç§»åŠ¨è‡³å¯¹åº”è¯´è¯äººåç§°çš„ç›®å½•ï¼Œæœªè¢«è¯†åˆ«çš„éŸ³é¢‘æ–‡ä»¶ä¼šç§»è‡³`Unrecognized`æ–‡ä»¶å¤¹ã€‚
- è¯†åˆ«ç»“æœä¹Ÿå°†ä¿å­˜ä¸º`result.json`æ–‡ä»¶ï¼Œå¯ä½¿ç”¨ Audio Dataset Screener å¯¼å…¥è¿›è¡Œè¿›ä¸€æ­¥çš„æ‰‹å·¥ç­›é€‰ã€‚

## âš– å¼€æºåè®®
åŸé¡¹ç›®åŸºäº [Apache License 2.0](https://github.com/yeyupiaoling/VoiceprintRecognition-Pytorch/blob/develop/LICENSE) å¼€æºï¼ŒæŒ‰ç…§è¯¥åè®®ï¼Œæœ¬é¡¹ç›®ä¸­åŸé¡¹ç›®çš„æºç é™„å¸¦æ–‡ä»¶ä¿®æ”¹è¯´æ˜ï¼ˆMODIFICATION_STATEMENTï¼‰ã€‚

æœ¬é¡¹ç›®åŸºäº [GNU General Public License v3.0](https://github.com/2DIPW/audio_dataset_vpr/blob/master/LICENSE) å¼€æº

*ä¸–ç•Œå› å¼€æºæ›´ç²¾å½©*
## ğŸ“ƒ å‚è€ƒæ–‡çŒ®
```
@inproceedings{desplanques2020ecapa,
  title={{ECAPA-TDNN: Emphasized Channel Attention, propagation and aggregation in TDNN based speaker verification}},
  author={Desplanques, Brecht and Thienpondt, Jenthe and Demuynck, Kris},
  booktitle={Interspeech 2020},
  pages={3830--3834},
  year={2020}
}
```